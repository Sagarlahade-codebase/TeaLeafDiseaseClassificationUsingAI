{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpTo9tVJEbIt",
        "outputId": "83f1118a-8bcd-4a25-f73f-92386f0b79c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.utils import get_custom_objects\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives +\n",
        "    K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "get_custom_objects().update({'f1_m': f1_m,'precision_m':precision_m, 'recall_m':recall_m})\n"
      ],
      "metadata": {
        "id": "66VFRM062T-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class labels for the training set\n",
        "from sklearn.svm import SVR\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def extract_features(file_path_resnet, file_path_googlenet, file_path_vgg16, train_batches_resnet, train_batches_googlenet, train_batches_vgg16):\n",
        "    # Load the pre-trained models\n",
        "    resnet_model = load_model(file_path_resnet)\n",
        "    googlenet_model = load_model(file_path_googlenet)\n",
        "    vgg16_model = load_model(file_path_vgg16)\n",
        "\n",
        "    # Freeze the layers in the models\n",
        "    for layer in resnet_model.layers:\n",
        "        layer.trainable = False\n",
        "    for layer in googlenet_model.layers:\n",
        "        layer.trainable = False\n",
        "    for layer in vgg16_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    #resnet_model.summary()\n",
        "    # Create a new model that outputs the flatten layer# Create a new model that outputs the flatten layer\n",
        "    resnet_output = resnet_model.layers[-2].output\n",
        "    resnet_feature_model = Model(inputs=resnet_model.input, outputs=resnet_output)\n",
        "\n",
        "    googlenet_output = googlenet_model.layers[-2].output\n",
        "    googlenet_feature_model = Model(inputs=googlenet_model.input, outputs=googlenet_output)\n",
        "\n",
        "    vgg16_flatten_layer = vgg16_model.layers[-2].output\n",
        "    vgg16_feature_model = Model(inputs=vgg16_model.input, outputs=vgg16_flatten_layer)\n",
        "\n",
        "    # Extract features from the models and use PCA to reduce the dimensionality of the features\n",
        "    #pca = PCA(n_components=174)\n",
        "\n",
        "    resnet_features = resnet_feature_model.predict(train_batches_resnet)\n",
        "    #reduced_resnet_features = pca.fit_transform(resnet_features)\n",
        "\n",
        "    googlenet_features = googlenet_feature_model.predict(train_batches_googlenet)\n",
        "    #reduced_googlenet_features = pca.fit_transform(googlenet_features)\n",
        "\n",
        "    vgg16_features = vgg16_feature_model.predict(train_batches_vgg16)\n",
        "    #reduced_vgg16_features = pca.fit_transform(vgg16_features)\n",
        "\n",
        "    # Combine the reduced features into a single feature set\n",
        "    features = np.concatenate((resnet_features, googlenet_features, vgg16_features), axis=1)\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "4pNU6lDGbno5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/TeaDataSetForML/train'\n",
        "test_path = '/content/drive/MyDrive/TeaDataSetForML/test'\n",
        "\n",
        "\n",
        "\n",
        "train_batches_vgg16 = ImageDataGenerator( rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ").flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
        "\n",
        "\n",
        "test_batches_vgg16 = ImageDataGenerator(rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "\n",
        "train_batches_googlenet = ImageDataGenerator( rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ").flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
        "test_batches_googlenet = ImageDataGenerator(rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "\n",
        "\n",
        "train_batches_resnet = ImageDataGenerator(rescale=1./25,preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
        "test_batches_resnet = ImageDataGenerator(rescale=1./25,preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjHMeaaNcVfL",
        "outputId": "1a8721f5-2606-4ca7-c978-d7152cba1363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 706 images belonging to 8 classes.\n",
            "Found 174 images belonging to 8 classes.\n",
            "Found 706 images belonging to 8 classes.\n",
            "Found 174 images belonging to 8 classes.\n",
            "Found 706 images belonging to 8 classes.\n",
            "Found 174 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "googlenet_path='/content/drive/MyDrive/TeaLeafNet/googlenetmodel9mar2023.h5'\n",
        "vgg16_path='/content/drive/MyDrive/TeaLeafNet/vgg16TeaLeaf.h5'\n",
        "resnet50_path='/content/drive/MyDrive/TeaLeafNet/resnet50Mar092023.h5'"
      ],
      "metadata": {
        "id": "O0IvDIN0fyMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features=extract_features(resnet50_path,googlenet_path,vgg16_path,train_batches_resnet,train_batches_googlenet,train_batches_vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_zdZqbXeOeU",
        "outputId": "b1ba36bc-c28f-4654-b676-b97fb1df1744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 126s 2s/step\n",
            "71/71 [==============================] - 69s 960ms/step\n",
            "71/71 [==============================] - 338s 5s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = []\n",
        "for i in range(train_batches_resnet.__len__()):\n",
        "    _, labels = train_batches_resnet.next()\n",
        "    integer_labels = np.argmax(labels, axis=1)\n",
        "    train_labels.append(integer_labels)\n",
        "train_labels = np.concatenate(train_labels, axis=0)"
      ],
      "metadata": {
        "id": "xoXd02noegfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features=extract_features(resnet50_path,googlenet_path,vgg16_path,test_batches_resnet,test_batches_googlenet,test_batches_vgg16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-EEiBxKiAx-",
        "outputId": "17cf84fa-0c0c-4565-fe04-47417e405c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 37s 2s/step\n",
            "18/18 [==============================] - 18s 924ms/step\n",
            "18/18 [==============================] - 84s 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = []\n",
        "for i in range(test_batches_resnet.__len__()):\n",
        "    _, labels = test_batches_resnet.next()\n",
        "    integer_labels = np.argmax(labels, axis=1)\n",
        "    test_labels.append(integer_labels)\n",
        "test_labels = np.concatenate(test_labels, axis=0)"
      ],
      "metadata": {
        "id": "tT6MTxEefXQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train=train_features\n",
        "print(\"train_features shape : \",train_features.shape)\n",
        "X_test=test_features\n",
        "print(\"test features shape : \",test_features.shape)\n",
        "\n",
        "y_train=train_labels\n",
        "print(\"len train labels : \",len(train_labels))\n",
        "y_test=test_labels\n",
        "print(\"len test labels : \",len(test_labels))\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "print(\"X_train[0] : \",X_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFbucwqwiXCd",
        "outputId": "3619155d-7b67-4e07-a586-7f38d16fad1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_features shape :  (706, 24)\n",
            "test features shape :  (174, 24)\n",
            "len train labels :  706\n",
            "len test labels :  174\n",
            "X_train[0] :  [0.00000000e+00 6.12075746e-01 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 9.46567535e-01 1.46871567e-01 8.12573433e-02\n",
            " 6.47220020e-07 3.35755394e-05 2.41159819e-06 1.30791295e-05\n",
            " 3.55093135e-07 1.69739479e-07 9.99051154e-01 9.52237286e-04\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.99999940e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "estimator = LinearRegression()\n",
        "selector = RFE(estimator, n_features_to_select=1000)\n",
        "X_selected = selector.fit_transform(X_train, y_train)\n",
        "print(\"X_selected shape : \",X_selected.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3JqAyrZk7vmY",
        "outputId": "fff5693b-092b-44d7-bc73-e8d6e5f42bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a840cbd6230c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_selected shape : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \"\"\"\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# Get importance and rank them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/linalg/_basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_lwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlapack_lwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001b[0m\u001b[1;32m   1214\u001b[0m                                                iwork, cond, False, False)\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# complex data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "estimator = LinearRegression()\n",
        "selector = RFE(estimator, n_features_to_select=1000)\n",
        "Y_selected = selector.fit_transform(X_test, y_test)\n",
        "print(\"Y_selected shape : \",Y_selected.shape)\n"
      ],
      "metadata": {
        "id": "F_7qsD2r97rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "# Gaussian kernel\n",
        "clf_rbf = SVC(kernel='rbf', gamma='auto')\n",
        "clf_rbf.fit(X_train, y_train)\n",
        "y_pred_rbf = clf_rbf.predict(X_test)\n",
        "print(y_pred_rbf)\n",
        "print(y_test)\n",
        "\n",
        "print(\"Accuracy with Gaussian kernel: \", accuracy_score(y_test, y_pred_rbf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66HfvWwEkXxD",
        "outputId": "a30fadd6-03e8-49c5-b7ac-3c7d50358b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 6 6 6 6 6 6 6 6 6 6 6 7 6 6 6 6\n",
            " 6 6 6 6 6 6 6 7 6 6 6 6 7 6 6 6 6 6 6 6 6 7 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 6 6 7 7 6 6 7 6 6 7 6 7 7 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 6 7 6 7 7 7 7 7 7 6 7 7 7 6 7 7 6 7 7 6 6 6 6 6 6 7]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
            "Accuracy with Gaussian kernel:  0.10919540229885058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create a Decision Tree model\n",
        "dt = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Fit the model on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "print(\"y train[0] : \",y_train)\n",
        "\n",
        "y_pred = dt.predict(X_test)\n",
        "print(\"y predication : \",y_pred)\n",
        "# Evaluate the model on the test data\n",
        "accuracy = dt.score(X_test, y_test)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1cX7eKGruAt",
        "outputId": "8a79aa9e-3306-46b9-b51a-3a09ddddf59a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y train[0] :  [1 7 3 7 6 1 1 5 2 2 1 4 6 6 3 7 1 7 7 2 1 7 5 6 1 1 6 6 3 0 6 0 1 2 1 6 3\n",
            " 2 3 6 1 7 5 5 5 0 3 4 5 4 7 5 2 2 4 6 4 0 7 2 2 2 0 0 4 6 7 2 2 2 2 3 5 3\n",
            " 1 2 1 0 6 4 5 6 6 5 3 5 7 3 4 7 1 5 4 5 1 2 0 4 7 3 7 3 6 0 5 2 6 6 5 1 1\n",
            " 1 2 6 7 5 1 0 0 6 4 0 0 4 6 6 0 6 2 5 0 7 1 1 1 1 1 3 2 1 4 6 3 4 4 2 2 2\n",
            " 1 1 4 3 6 6 0 7 0 4 4 3 3 3 6 7 7 4 4 5 0 2 1 5 4 5 0 6 4 5 6 3 4 5 7 0 7\n",
            " 6 1 7 4 3 7 2 3 6 6 6 1 7 4 2 7 3 2 5 1 3 7 0 5 4 3 1 7 3 2 6 5 7 7 0 2 4\n",
            " 3 6 6 0 0 3 6 7 7 0 3 6 6 4 7 1 7 0 0 3 0 3 7 4 3 3 7 2 4 3 6 4 1 0 6 4 1\n",
            " 2 7 1 7 5 7 5 6 4 5 0 3 6 7 1 1 3 1 4 6 6 6 6 2 4 0 3 0 0 0 0 3 2 1 7 2 2\n",
            " 5 7 7 0 7 4 0 6 4 2 5 0 7 2 4 4 1 1 2 0 6 6 4 4 4 4 1 2 6 3 2 2 5 4 3 7 0\n",
            " 3 0 3 2 5 5 6 0 5 1 4 3 6 0 1 1 3 1 6 2 4 7 7 6 6 1 6 0 2 4 3 2 1 1 2 1 6\n",
            " 7 5 1 5 0 4 7 0 7 7 0 4 6 1 0 7 2 0 1 6 6 4 7 1 0 1 3 4 2 6 6 5 0 2 7 7 2\n",
            " 6 2 6 3 6 1 7 0 7 7 3 4 3 4 3 6 6 0 3 6 7 6 6 5 5 6 6 3 2 5 0 7 1 2 7 7 4\n",
            " 1 1 2 2 0 4 7 3 2 0 7 1 3 1 7 7 0 7 0 7 6 2 2 7 2 7 6 7 4 0 6 3 1 3 1 2 3\n",
            " 1 3 4 6 1 6 2 6 4 6 3 3 1 3 5 4 0 7 6 4 1 6 6 3 2 4 0 6 2 4 5 1 1 7 3 7 5\n",
            " 7 4 3 7 6 6 2 7 6 0 1 7 0 4 4 7 4 6 1 2 5 7 6 5 6 1 0 6 6 3 3 4 2 3 6 1 7\n",
            " 5 5 0 0 4 7 6 7 7 2 6 7 6 6 0 0 7 0 7 0 1 1 4 0 6 4 3 3 2 3 1 7 7 7 5 4 7\n",
            " 1 7 1 5 3 7 7 7 6 1 5 0 7 3 3 6 7 5 4 3 3 7 7 7 5 6 3 0 1 6 3 6 7 3 1 1 7\n",
            " 4 3 5 1 6 2 0 3 6 6 0 6 7 4 4 1 7 2 2 2 3 3 7 6 3 1 3 3 6 2 2 2 7 0 5 6 3\n",
            " 4 0 7 3 2 6 2 0 5 7 3 1 6 4 5 0 7 6 2 4 2 7 4 3 4 6 5 7 3 7 1 1 1 5 6 0 3\n",
            " 7 5 2]\n",
            "y predication :  [7 7 7 7 7 7 7 6 1 7 1 3 7 7 3 7 7 3 7 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 6 7 6 6 7 7 6 7 7 7 6 6 2 6 6 6 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 1 7 7 1 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
            "Accuracy: 16.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "f9gJnZ_1WfS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train a Random Forest classifier with 100 trees\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "print(y_pred)\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6HxfGpNWfmW",
        "outputId": "b6d5d156-c2a8-4db3-d039-27f5383f1d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 4 0 1 1 1 0 1 4 1 1 1 4 1 1 1 6 2 2 6 2 3 3 2 6 0 3 3 3 6 3 4 3\n",
            " 7 3 3 6 5 6 4 1 4 4 6 4 1 6 0 4 4 4 1 4 6 1 1 6 4 1 0 2 2 3 4 7 0 3 2 0 2\n",
            " 1 7 2 0 6 3 2 6 2 2 4 1 2 1 1 5 4 4 1 7 0 1 1 4 1 7 4 1 1 1 6 6 3 3 6 6 6\n",
            " 6 6 6 6 3 6 6 7 7 2 7 7 3 7 2 6 7 1 7 7 4 7 6 2 2 7 7 7 3 1 7 7 6 4 7 1 7\n",
            " 3 1 7 7 6 7 7 2 6 4 7 2 3 1 7 7 7 7 2 6 2 3 4 3 1 6]\n",
            "Accuracy: 0.13218390804597702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Create a Gaussian Naive Bayes classifier and fit it to the training data\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to make predictions on the testing data\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJFAY7DRaa-v",
        "outputId": "629f36f5-9cc9-40eb-e369-ab5d4cb260cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.22413793103448276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "!pip install scikit-fuzzy\n",
        "!pip install --upgrade scikit-fuzzy\n",
        "import skfuzzy as fuzz\n",
        "from fuzz import classifier, cluster\n",
        "import numpy as np\n",
        "\n",
        "#Create FMM classifier\n",
        "fmm = classifier.FuzzyClassifier(c=2.0, m=2.0)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "fmm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = fmm.predict(X_test)\n",
        "\n",
        "# Print the predicted classes\n",
        "print(y_pred)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "7Znzx7JmrDzM",
        "outputId": "ec28421c-124b-48cf-d8d5-79308580d23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.9/dist-packages (0.4.2)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from scikit-fuzzy) (3.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from scikit-fuzzy) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from scikit-fuzzy) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.9/dist-packages (0.4.2)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from scikit-fuzzy) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from scikit-fuzzy) (1.22.4)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from scikit-fuzzy) (3.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-0f2a681e9d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade scikit-fuzzy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskfuzzy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzz'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model, load_model\n",
        "from keras.layers import concatenate, Average, Dense, Input, multiply\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import plot_model\n",
        "from keras.layers import Flatten, Reshape\n",
        "from keras.utils import Sequence\n",
        "\n",
        "\n",
        "# Load the pre-trained models\n",
        "googlenet = load_model(googlenet_path)\n",
        "vgg16 = load_model(vgg16_path)\n",
        "resnet50 = load_model(resnet50_path)\n",
        "\n",
        "# Rename the common layers in each model\n",
        "for layer in googlenet.layers:\n",
        "    layer._name = 'googlenet_' + layer.name\n",
        "for layer in vgg16.layers:\n",
        "    layer._name = 'vgg16_' + layer.name\n",
        "for layer in resnet50.layers:\n",
        "    layer._name = 'resnet50_' + layer.name\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in googlenet.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "for layer in vgg16.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "for layer in resnet50.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model that combines the outputs of the pre-trained models\n",
        "\n",
        "googlenet_output = Flatten()(googlenet.get_layer('googlenet_avg_pool_5_3x3/1').output)\n",
        "print(\"googlenet_output.shape\",googlenet_output.shape)\n",
        "vgg16_output = Flatten()(vgg16.get_layer('vgg16_block5_pool').output)\n",
        "print(\"vgg16_output.shape\",vgg16_output.shape)\n",
        "\n",
        "resnet50_output = Flatten()(resnet50.get_layer('resnet50_average_pooling2d_6').output)\n",
        "print(\"resnet50_output.shape\",resnet50_output.shape)\n",
        "\n",
        "\n",
        "merged_output = concatenate([googlenet_output, vgg16_output, resnet50_output])\n",
        "print(\"merged_output\",merged_output)\n",
        "dense1= Dense(256, activation='softmax')(merged_output)\n",
        "output_tensor = Dense(8, activation='softmax')(dense1)\n",
        "\n",
        "print(\"googlenet input \",googlenet.input)\n",
        "print(\"vgg16 input \",vgg16.input)\n",
        "print(\"resnet50 input \",resnet50.input)\n",
        "\n",
        "\n",
        "hybrid_model = Model(inputs=[googlenet.input, vgg16.input, resnet50.input], outputs=output_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktZyGSTO0FPk",
        "outputId": "81236390-13b6-4cd4-c0ae-2df009daaa19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "googlenet_output.shape (None, 1024)\n",
            "vgg16_output.shape (None, 25088)\n",
            "resnet50_output.shape (None, 32768)\n",
            "merged_output KerasTensor(type_spec=TensorSpec(shape=(None, 58880), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
            "googlenet input  KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'googlenet_input_1'\")\n",
            "vgg16 input  KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "resnet50 input  KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_7'), name='input_7', description=\"created by layer 'resnet50_input_7'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/TeaDataSet/train'\n",
        "valid_path = '/content/drive/MyDrive/TeaDataSet/valid'\n",
        "test_path = '/content/drive/MyDrive/TeaDataSet/test'\n",
        "\n",
        "\n",
        "train_batches_vgg16 = ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ").flow_from_directory(train_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "valid_batches_vgg16 = ImageDataGenerator(rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "test_batches_vgg16 = ImageDataGenerator(rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10,shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODPSwjP5AhFX",
        "outputId": "8cf65d5d-1b64-4193-f306-d0ec799e7c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 706 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches_googlenet = ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ").flow_from_directory(train_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "valid_batches_googlenet = ImageDataGenerator(rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "test_batches_googlenet = ImageDataGenerator(rescale=1./255,preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10,shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2Qg-F-RBYMr",
        "outputId": "8bfc6134-0c1b-4f0b-c4a2-66a0205e4307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 706 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches_resnet = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(train_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "valid_batches_resnet = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(valid_path, target_size=(224,224), batch_size=10,shuffle=False)\n",
        "test_batches_resnet = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input).flow_from_directory(test_path, target_size=(224,224), batch_size=10,shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKYdmjx-BgEz",
        "outputId": "284c04d9-8581-4d08-9300-cd43d3caf0b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 706 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_generator(generator):\n",
        "    while True:\n",
        "        \"\"\"batch_images, batch_labels = next(generator)\n",
        "        batch_resnet_input = resnet_generator.preprocessing_function(batch_images.copy())\n",
        "        batch_vgg_input = vgg_generator.preprocessing_function(batch_images.copy())\n",
        "        batch_googlenet_input = googlenet_generator.preprocessing_function(batch_images.copy())\"\"\"\n",
        "\n",
        "        #batch_images, batch_labels = next(generator)\n",
        "        resnet_batch_images,resnet_batch_labels = next(train_batches_resnet)\n",
        "        googlenet_batch_images,googlenet_batch_labels=next(train_batches_googlenet)\n",
        "        vgg16_batch_images,vgg16_batch_labels=next(train_batches_vgg16)\n",
        "        yield [googlenet_batch_images, vgg16_batch_images, resnet_batch_images], googlenet_batch_labels\n"
      ],
      "metadata": {
        "id": "V012-uSaBwqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_generatorValid(generator):\n",
        "    while True:\n",
        "\n",
        "        resnet_batch_images,resnet_batch_labels = next(valid_batches_resnet)\n",
        "        googlenet_batch_images,googlenet_batch_labels=next(valid_batches_googlenet)\n",
        "        vgg16_batch_images,vgg16_batch_labels=next(valid_batches_vgg16)\n",
        "        yield [googlenet_batch_images, vgg16_batch_images, resnet_batch_images], googlenet_batch_labels\n"
      ],
      "metadata": {
        "id": "Ddlbs1R1Oxlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_generator=ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n",
        "\n",
        "vgg_generator=ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ")\n",
        "\n",
        "\n",
        "googlenet_generator= ImageDataGenerator( rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "QQ1QFixHCVgP",
        "outputId": "50c7a4ec-b593-4672-83cc-5c1e19a95f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-88062e6c56b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresnet_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessing_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m vgg_generator=ImageDataGenerator( rescale=1./255,\n\u001b[1;32m      4\u001b[0m     \u001b[0mrotation_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwidth_shift_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z11LDuM5Cy8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches_custom_generator  = ImageDataGenerator( ).flow_from_directory(train_path, target_size=(224,224), batch_size=10)\n",
        "valid_batches_custom_generator  = ImageDataGenerator( ).flow_from_directory(valid_path, target_size=(224,224), batch_size=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZoX0eBDDWUu",
        "outputId": "9c2cde70-554e-43e6-d98c-423876721933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 706 images belonging to 8 classes.\n",
            "Found 87 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the new model\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "epochs = 100\n",
        "initial_lrate = 0.001\n",
        "def decay(epoch, steps=100):\n",
        "  initial_lrate = 0.01\n",
        "  drop = 0.96\n",
        "  epochs_drop = 8\n",
        "  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "  return lrate\n",
        "sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False)\n",
        "\n",
        "\n",
        "hybrid_model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "callback_list=[EarlyStopping(monitor=\"val_loss\",patience=250),ModelCheckpoint(filepath=\"/content/drive/MyDrive/TeaLeafNetV2.0sagarlogin.h5\",monitor=\"val_loss\",save_best_only=True,verbose=1)]\n",
        "\n",
        "hybrid_model.fit_generator(custom_generator(train_batches_googlenet), epochs=1000, validation_data=custom_generatorValid(valid_batches_googlenet),verbose=1,callbacks=callback_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjfcbB7OC_UE",
        "outputId": "100d1c47-a37c-4bb3-8959-cda8a2b138e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "<ipython-input-15-fb014b195d5a>:23: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hybrid_model.fit_generator(custom_generator(train_batches_googlenet), epochs=1000, validation_data=custom_generatorValid(valid_batches_googlenet),verbose=1,callbacks=callback_list)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "   1608/Unknown - 16391s 10s/step - loss: 2.1066 - accuracy: 0.0375"
          ]
        }
      ]
    }
  ]
}